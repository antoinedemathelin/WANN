{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WANN experiments on UCI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.constraints import MinMaxNorm\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "sys.path.append(\"../wann\")\n",
    "from utils import superconduct, domain, BaggingModels, cross_val\n",
    "from uci_experiments import run_uci_experiments\n",
    "from methods import *\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 0  # possible values: 0, 1, 2, 3\n",
    "target = 2  # possible values: 0, 1, 2, 3\n",
    "\n",
    "N = 10   # Number of labeled target data\n",
    "\n",
    "data, X, y, cuts, split_col = superconduct()\n",
    "shape = X.shape[1]\n",
    "\n",
    "src_index = domain(data, cuts, split_col, source)\n",
    "tgt_index = domain(data, cuts, split_col, target)\n",
    "\n",
    "np.random.seed(0)\n",
    "tgt_train_index, tgt_test_index = train_test_split(tgt_index, train_size=N)\n",
    "train_index = np.concatenate((src_index, tgt_train_index))\n",
    "\n",
    "std_sc = StandardScaler()\n",
    "std_sc.fit(X[train_index])\n",
    "X = std_sc.transform(X)\n",
    "y = (y - y[train_index].mean()) / y[train_index].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model(shape, activation=None, C=1, name=\"BaseModel\"):\n",
    "    inputs = Input(shape=(shape,))\n",
    "    modeled = Dense(100, activation='relu',\n",
    "                         kernel_constraint=MinMaxNorm(0, C),\n",
    "                         bias_constraint=MinMaxNorm(0, C))(inputs)\n",
    "    modeled = Dense(1, activation=activation,\n",
    "                    kernel_constraint=MinMaxNorm(0, C),\n",
    "                    bias_constraint=MinMaxNorm(0, C))(modeled)\n",
    "    model = Model(inputs, modeled, name=name)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def get_encoder(shape, C=1, name=\"encoder\"):\n",
    "    inputs = Input(shape=(shape,))\n",
    "    modeled = Dense(100, activation='relu',\n",
    "                         kernel_constraint=MinMaxNorm(0, C),\n",
    "                         bias_constraint=MinMaxNorm(0, C))(inputs)\n",
    "    model = Model(inputs, modeled)\n",
    "    model.compile(optimizer=\"adam\", loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def get_task(shape, C=1, activation=None, name=\"task\"):\n",
    "    inputs = Input(shape=(shape,))\n",
    "    modeled = Dense(1, activation=activation,\n",
    "                         kernel_constraint=MinMaxNorm(0, C),\n",
    "                         bias_constraint=MinMaxNorm(0, C))(inputs)\n",
    "    model = Model(inputs, modeled)\n",
    "    model.compile(optimizer=\"adam\", loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "base_estimator = BaggingModels(func=get_base_model,\n",
    "                               n_models=1,\n",
    "                               n_jobs=None,\n",
    "                               shape=shape,\n",
    "                               C=1,\n",
    "                               random_state=0)\n",
    "fit_params = dict(epochs=200,\n",
    "                  batch_size=1000,\n",
    "                  verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target score: 0.372\n"
     ]
    }
   ],
   "source": [
    "tgt_only = copy.deepcopy(base_estimator)\n",
    "tgt_only.fit(X[tgt_train_index], y[tgt_train_index], **fit_params)\n",
    "\n",
    "y_pred = tgt_only.predict(X)\n",
    "score= mean_squared_error(y[tgt_test_index], y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target score: 0.501\n"
     ]
    }
   ],
   "source": [
    "src_only = copy.deepcopy(base_estimator)\n",
    "src_only.fit(X[src_index], y[src_index], **fit_params)\n",
    "\n",
    "y_pred = src_only.predict(X)\n",
    "score= mean_squared_error(y[tgt_test_index], y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No reweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target score: 0.453\n"
     ]
    }
   ],
   "source": [
    "no_reweight = copy.deepcopy(base_estimator)\n",
    "no_reweight.fit(X[train_index], y[train_index], **fit_params)\n",
    "\n",
    "y_pred = no_reweight.predict(X)\n",
    "score= mean_squared_error(y[tgt_test_index], y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BalancedWeighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target score: 0.390\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "balanced = BalancedWeighting(get_base_model)\n",
    "balanced.fit(X, y, [src_index, tgt_train_index], **fit_params)\n",
    "\n",
    "y_pred = balanced.predict(X)\n",
    "score= mean_squared_error(y[tgt_test_index], y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target score: 0.745\n"
     ]
    }
   ],
   "source": [
    "dann = BaggingModels(DANN, n_models=1, n_jobs=None, random_state=0,\n",
    "                     get_encoder=get_encoder, get_task=get_task, lambda_=0.05)\n",
    "\n",
    "dann.fit(X, y, index=[src_index, tgt_index, tgt_train_index], **fit_params)\n",
    "\n",
    "y_pred = dann.predict(X)\n",
    "score = mean_squared_error(y[tgt_test_index], y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target score: 0.793\n"
     ]
    }
   ],
   "source": [
    "adda = BaggingModels(ADDA, n_models=1, n_jobs=None, random_state=0, optimizer=Adam(0.00001),\n",
    "                     get_encoder=get_encoder, get_task=get_task, get_discriminer=get_task)\n",
    "\n",
    "adda.fit(X, y, index=[src_index, tgt_index, tgt_train_index], **fit_params)\n",
    "\n",
    "y_pred = adda.predict(X)\n",
    "score = mean_squared_error(y[tgt_test_index], y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target score: 0.395\n"
     ]
    }
   ],
   "source": [
    "mcd = BaggingModels(MCD, n_models=1, n_jobs=None, random_state=0,\n",
    "                     get_encoder=get_encoder, get_task=get_task, lambda_=0.1)\n",
    "\n",
    "mcd.fit(X, y, index=[src_index, tgt_index, tgt_train_index], **fit_params)\n",
    "\n",
    "y_pred = mcd.predict(X)\n",
    "score = mean_squared_error(y[tgt_test_index], y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target score: 0.820\n"
     ]
    }
   ],
   "source": [
    "mdd = BaggingModels(MDD, n_models=1, n_jobs=None, random_state=0,\n",
    "                     get_encoder=get_encoder, get_task=get_task, lambda_=0.1)\n",
    "\n",
    "mdd.fit(X, y, index=[src_index, tgt_index, tgt_train_index], **fit_params)\n",
    "\n",
    "y_pred = mdd.predict(X)\n",
    "score = mean_squared_error(y[tgt_test_index], y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target score: 0.289\n"
     ]
    }
   ],
   "source": [
    "wann = BaggingModels(WANN, n_models=1, n_jobs=None, random_state=0,\n",
    "                     get_base_model=get_base_model, C=1, C_w=0.1)\n",
    "\n",
    "wann.fit(X, y, index=[src_index, tgt_train_index], **fit_params)\n",
    "\n",
    "y_pred = wann.predict(X)\n",
    "score = mean_squared_error(y[tgt_test_index],\n",
    "                           y_pred[tgt_test_index])\n",
    "print('Target score: %.3f'%score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment for method: WANN\n",
      "\n",
      "\n",
      "############# 0 #############\n",
      "--------- 1 ----------\n",
      "Target_score: 0.233\n",
      "--------- 2 ----------\n",
      "Target_score: 0.289\n",
      "--------- 3 ----------\n",
      "Target_score: 0.334\n",
      "############# 1 #############\n",
      "--------- 0 ----------\n",
      "Target_score: 0.435\n",
      "--------- 2 ----------\n",
      "Target_score: 0.258\n",
      "--------- 3 ----------\n",
      "Target_score: 0.371\n",
      "############# 2 #############\n",
      "--------- 0 ----------\n",
      "Target_score: 0.599\n",
      "--------- 1 ----------\n",
      "Target_score: 0.395\n",
      "--------- 3 ----------\n",
      "Target_score: 0.355\n",
      "############# 3 #############\n",
      "--------- 0 ----------\n",
      "Target_score: 0.636\n",
      "--------- 1 ----------\n",
      "Target_score: 0.502\n",
      "--------- 2 ----------\n",
      "Target_score: 0.325\n"
     ]
    }
   ],
   "source": [
    "# Add unlabeled sample \n",
    "\n",
    "df = run_uci_experiments(method=\"WANN\",\n",
    "                         get_base_model=get_base_model,\n",
    "                         get_encoder=get_encoder,\n",
    "                         get_task=get_task,\n",
    "                         C=1,\n",
    "                         C_w=0.1,\n",
    "                         lambda_=0.1,\n",
    "                         sigma=0.1,\n",
    "                         epochs=200,\n",
    "                         batch_size=1000,\n",
    "                         n_models=1,\n",
    "                         n_jobs=None,\n",
    "                         n_target_labeled=10,\n",
    "                         random_state=0,\n",
    "                         save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch all experiments (all methods, 10 times)\n",
    "Uncomment cell below to launch experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ..\\wann\\uci_experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wann",
   "language": "python",
   "name": "wann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
