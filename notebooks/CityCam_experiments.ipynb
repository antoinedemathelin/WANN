{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Conv2D, MaxPooling2D, Flatten, Reshape, GaussianNoise, Conv2DTranspose, LeakyReLU\n",
    "from tensorflow.keras.constraints import MinMaxNorm\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../wann/methods\")\n",
    "from WANN import WANN\n",
    "\n",
    "from adapt.instance_based import KLIEP, KMM, TrAdaBoostR2\n",
    "from adapt.feature_based import MDD, DANN, ADDA, DeepCORAL\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_files(domains):   \n",
    "    for domain in domains:\n",
    "        path = \"../dataset/citycam/%s\"%domain\n",
    "        for r, d, f in os.walk(path):\n",
    "            for direct in d:\n",
    "                if \"checkpoints\" not in direct:\n",
    "                    x_path = path + \"/\" + direct + \"/\" + \"X.npy\"\n",
    "                    y_path = path + \"/\" + direct + \"/\" + \"y.npy\"\n",
    "\n",
    "                    Xi = np.load(x_path)\n",
    "                    yi = np.load(y_path)\n",
    "                    \n",
    "                    if len(yi) != len(Xi):\n",
    "                        print(len(yi), len(Xi))\n",
    "\n",
    "                    try:\n",
    "                        X = np.concatenate((X, Xi))\n",
    "                        y = np.concatenate((y, yi))\n",
    "                    except:\n",
    "                        X = np.copy(Xi)\n",
    "                        y = np.copy(yi)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model(shape=2048, activation=None, C=1., name=\"BaseModel\"):\n",
    "    inputs = Input(shape=(shape,))\n",
    "    modeled = Dense(100, activation='relu',\n",
    "                         kernel_constraint=MinMaxNorm(0, C),\n",
    "                         bias_constraint=MinMaxNorm(0, C))(inputs)\n",
    "    modeled = Dense(100, activation='relu',\n",
    "                    kernel_constraint=MinMaxNorm(0, C),\n",
    "                    bias_constraint=MinMaxNorm(0, C))(modeled)\n",
    "    modeled = Dense(1, activation=activation,\n",
    "                    kernel_constraint=MinMaxNorm(0, C),\n",
    "                    bias_constraint=MinMaxNorm(0, C))(modeled)\n",
    "    model = Model(inputs, modeled, name=name)\n",
    "    model.compile(optimizer=Adam(0.001), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_encoder(shape=2048, C=1, name=\"encoder\"):\n",
    "    inputs = Input(shape=(shape,))\n",
    "    modeled = Dense(100, activation='relu',\n",
    "                         kernel_constraint=MinMaxNorm(0, C),\n",
    "                         bias_constraint=MinMaxNorm(0, C))(inputs)\n",
    "    model = Model(inputs, modeled)\n",
    "    model.compile(optimizer=\"adam\", loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_task(shape=100, C=1, activation=None, name=\"task\"):\n",
    "    inputs = Input(shape=(shape,))\n",
    "    modeled = Dense(100, activation='relu',\n",
    "                    kernel_constraint=MinMaxNorm(0, C),\n",
    "                    bias_constraint=MinMaxNorm(0, C))(inputs)\n",
    "    modeled = Dense(1, activation=activation,\n",
    "                         kernel_constraint=MinMaxNorm(0, C),\n",
    "                         bias_constraint=MinMaxNorm(0, C))(modeled)\n",
    "    model = Model(inputs, modeled)\n",
    "    model.compile(optimizer=\"adam\", loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = [\"253\", \"511\", \"572\"]\n",
    "target = [\"495\"]\n",
    "\n",
    "Xs, ys = concat_files(source)\n",
    "Xt, yt = concat_files(target)\n",
    "\n",
    "Xs = Xs.astype(np.float64)\n",
    "Xt = Xt.astype(np.float64)\n",
    "ys = ys.astype(np.float64)\n",
    "yt = yt.astype(np.float64)\n",
    "\n",
    "X = np.concatenate((Xs, Xt))\n",
    "y = np.concatenate((ys, yt))\n",
    "\n",
    "src_index = np.array(range(len(ys)))\n",
    "tgt_index = np.array(range(len(ys), len(ys) + len(yt)))\n",
    "\n",
    "std_sc = StandardScaler()\n",
    "std_sc.fit(X[src_index])\n",
    "\n",
    "X = std_sc.transform(X)\n",
    "\n",
    "mu = ys.mean()\n",
    "std = ys.std()\n",
    "\n",
    "y = (y - mu) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "seeds = np.random.choice(2**16, 10)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "\n",
    "for n_target_labeled in [20, 50, 100, 200]:\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        np.random.seed(seeds[i])\n",
    "        tf.random.set_seed(seeds[i])\n",
    "\n",
    "        tgt_index_labeled = np.random.choice(tgt_index, n_target_labeled, replace=False)\n",
    "        train_index = np.concatenate((src_index, tgt_index_labeled))\n",
    "\n",
    "        for method in [\"WANN\", \"TgtOnly\", \"NoReweight\", \"KLIEP\", \"KMM\", \"DANN\", \"ADDA\", \"DeepCORAL\", \"MDD\", \"TrAdaBoostR2\"]: # \"WANN\", \"TgtOnly\", \"NoReweight\", \"KLIEP\", \"KMM\", \"DANN\", \"ADDA\", \"DeepCORAL\", \"MDD\", \"TrAdaBoostR2\"\n",
    "            print(method)\n",
    "            if not method in scores:\n",
    "                scores[method] = []\n",
    "\n",
    "            if method in [\"TgtOnly\", \"NoReweight\"]:            \n",
    "                model = get_base_model(shape=X.shape[1])\n",
    "\n",
    "                if method == \"TgtOnly\":\n",
    "                    model.fit(X[tgt_index_labeled], y[tgt_index_labeled], epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "                if method == \"NoReweight\":\n",
    "                    model.fit(X[train_index], y[train_index], epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "            elif method in [\"WANN\"]:\n",
    "                model = WANN(get_base_model=get_base_model, C=1., optimizer=Adam(0.001))   \n",
    "                model.fit(X, y, [train_index, tgt_index_labeled], epochs=epochs, verbose=0, batch_size=batch_size)\n",
    "            \n",
    "            elif method == \"TrAdaBoostR2\":\n",
    "                model = TrAdaBoostR2(get_base_model(), verbose=2, random_state=seeds[i])\n",
    "                model.fit(X[train_index], y[train_index], X[tgt_index_labeled], y[tgt_index_labeled],\n",
    "                          epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "            else:            \n",
    "                if method == \"DANN\":\n",
    "                    model = DANN(encoder=get_encoder(), task=get_task(), random_state=seeds[i],\n",
    "                                 discriminator=get_task(activation=\"sigmoid\"),\n",
    "                                 optimizer=Adam(0.001), lambda_=0.1, loss=\"mse\")\n",
    "                if method == \"DeepCORAL\":\n",
    "                    model = DeepCORAL(encoder=get_encoder(), task=get_task(), lambda_=10.,\n",
    "                                      optimizer=Adam(0.001), loss=\"mse\",\n",
    "                                      random_state=seeds[i])\n",
    "                if method == \"MDD\":\n",
    "                    model = MDD(encoder=get_encoder(), task=get_task(), random_state=seeds[i],\n",
    "                                optimizer=Adam(0.001), lambda_=0.0001, loss=\"mse\")\n",
    "                if method == \"ADDA\":\n",
    "                    encoder = get_encoder()\n",
    "                    task=get_task()\n",
    "                    discriminator=get_task(activation=\"sigmoid\")\n",
    "                    dann = DANN(encoder, task, discriminator, loss=\"mse\", copy=False,\n",
    "                                lambda_=0., random_state=seeds[i])\n",
    "                    dann.fit(X[train_index], y[train_index], X[tgt_index], epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "                    model = ADDA(encoder=encoder, task=task,\n",
    "                                 discriminator=discriminator, random_state=seeds[i],\n",
    "                                 is_pretrained=True,\n",
    "                                 optimizer=Adam(0.0001), loss=\"mse\")\n",
    "                if method == \"KLIEP\":\n",
    "                    model = KLIEP(get_base_model(), sigmas=0.001, random_state=seeds[i])\n",
    "                if method == \"KMM\":\n",
    "                    model = KMM(get_base_model(), kernel_params=dict(gamma=0.001), verbose=0, random_state=seeds[i])\n",
    "\n",
    "                model.fit(X[train_index], y[train_index], X[tgt_index], epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "            err_s = np.mean(np.abs(model.predict(X).ravel()[src_index] - y[src_index]) * std)\n",
    "            err_t = np.mean(np.abs(model.predict(X).ravel()[tgt_index] - y[tgt_index]) * std)\n",
    "\n",
    "            scores[method].append(err_t)\n",
    "\n",
    "            print(\"source %.3f\"%err_s)\n",
    "            print(\"target %.3f\"%err_t)\n",
    "    \n",
    "    print(pd.DataFrame(scores).describe())\n",
    "    pd.DataFrame(scores).to_csv(\"../dataset/results/citycam_%i.csv\"%n_target_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statmath38",
   "language": "python",
   "name": "statmath38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
